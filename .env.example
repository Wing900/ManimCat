# =============================================================================
# ManimCat 配置文件说明
# =============================================================================
# 优先级说明：CUSTOM_API_URL 优先级最高
# - 如果设置了 CUSTOM_API_URL：使用自定义的 OpenAI 兼容 API 端点
# - 如果 CUSTOM_API_URL 为空：使用官方 OpenAI API (https://api.openai.com/v1)
# =============================================================================

# -----------------------------------------------------------------------------
# 认证配置（可选）
# -----------------------------------------------------------------------------
# MANIMCAT_API_KEY: 用于保护 API 端点的自定义密钥
# - 设置此值可以防止未经授权的访问
# - 为空时跳过认证
# - 如果在这里设置，前端设置中必须使用相同的值
MANIMCAT_API_KEY=

# -----------------------------------------------------------------------------
# AI 服务配置（必填）
# -----------------------------------------------------------------------------
# OPENAI_API_KEY: AI 代码生成所需的 API 密钥
# - 使用官方 OpenAI 或自定义兼容 API 时都需要填写
# - 官方 OpenAI：从 https://platform.openai.com/api-keys 获取
# - 自定义 API：使用你的服务提供商提供的密钥
OPENAI_API_KEY=your-openai-api-key-here

# OPENAI_MODEL: 使用的 AI 模型（可选，默认值：glm-4-flash）
# - 支持任何 OpenAI 兼容的模型
# - 官方 OpenAI 示例：gpt-4o-mini, gpt-4o, gpt-3.5-turbo
# - 第三方服务示例：glm-4-flash（智谱 AI）, @minimaxai/minimax-m2.1
# - 本地模型：使用你的自定义 API 支持的任何模型名称
OPENAI_MODEL=glm-4-flash

# CUSTOM_API_URL: 自定义 OpenAI 兼容 API 端点（可选）
# - 优先级最高：如果设置，则使用此端点而非官方 OpenAI API
# - 为空时使用：https://api.openai.com/v1（官方 OpenAI）
# - 必须兼容 OpenAI API（支持 /chat/completions 端点）
# - 常见示例：
#   - Together AI：https://api.together.xyz/v1
#   - LocalAI：http://localhost:8080/v1
#   - Ollama：http://localhost:11434/v1
#   - 第三方代理：https://proxy/bin/nvidia/v1
CUSTOM_API_URL=

# -----------------------------------------------------------------------------
# AI 参数配置（可选）
# -----------------------------------------------------------------------------
# AI_TEMPERATURE: 控制 AI 输出的随机性（默认值：0.7）
# - 取值范围：0.0 - 2.0
# - 数值越低：输出越确定、越聚焦
# - 数值越高：输出越有创意、越多样
# AI_TEMPERATURE=0.7

# AI_MAX_TOKENS: AI 响应的最大 token 数（默认值：1200）
# AI_MAX_TOKENS=1200

# OPENAI_TIMEOUT: 请求超时时间（毫秒）（默认值：600000）
# OPENAI_TIMEOUT=600000

# -----------------------------------------------------------------------------
# 两阶段 AI 生成配置
# -----------------------------------------------------------------------------
# DESIGNER_TEMPERATURE: 概念设计者的温度参数（默认值：0.8）
# - 比代码生成者稍高，以获得更有创意的场景设计
# DESIGNER_TEMPERATURE=0.8

# DESIGNER_MAX_TOKENS: 概念设计者的最大 token 数（默认值：800）
# DESIGNER_MAX_TOKENS=800

# -----------------------------------------------------------------------------
# 应用设置
# -----------------------------------------------------------------------------
# NODE_ENV: 运行环境
# - development（开发环境）
# - production（生产环境）
NODE_ENV=development

# -----------------------------------------------------------------------------
# 媒体清理配置（可选）
# -----------------------------------------------------------------------------
# MEDIA_RETENTION_HOURS: 图片/视频文件保留小时数（默认 72）
# MEDIA_RETENTION_HOURS=72

# MEDIA_CLEANUP_INTERVAL_MINUTES: 清理任务执行间隔（分钟，默认 60）
# MEDIA_CLEANUP_INTERVAL_MINUTES=60

# -----------------------------------------------------------------------------
# 任务明细与用量统计保留配置（可选）
# -----------------------------------------------------------------------------
# JOB_RESULT_RETENTION_HOURS: 任务结果与阶段信息在 Redis 中保留小时数（默认 24）
# JOB_RESULT_RETENTION_HOURS=24

# USAGE_RETENTION_DAYS: 按天聚合的用量统计保留天数（默认 90）
# USAGE_RETENTION_DAYS=90

# METRICS_USAGE_RATE_LIMIT_MAX: 用量接口每个 IP 在窗口期内允许的最大请求数（默认 30）
# METRICS_USAGE_RATE_LIMIT_MAX=30

# METRICS_USAGE_RATE_LIMIT_WINDOW_MS: 用量接口限流窗口时长（毫秒，默认 60000）
# METRICS_USAGE_RATE_LIMIT_WINDOW_MS=60000

